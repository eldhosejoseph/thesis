{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvk4uSxP7ZvK4XhMFbFxER",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eldhosejoseph/thesis/blob/main/Dryad_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DRYAD DATASET"
      ],
      "metadata": {
        "id": "OHAvXCVcY6lq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Data from: A novel algorithm to enhance P300 in single trials: application to lie detection using F-score and SVM] : https://datadryad.org/stash/dataset/doi:10.5061/dryad.2qc64\n",
        "\n",
        "paper: https://doi.org/10.1371/journal.pone.0109700"
      ],
      "metadata": {
        "id": "8ZTMMU7BZDkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EEG Data Acquisition**\n",
        "\n",
        "Twelve electrodes (Fp1, Fp2, F3, Fz, F4, C3, Cz, C4, P3, Pz, P4, Oz) from an International 10–20 system were used. The vertical EOG (VEOG) signal was recorded from the right eye (2.5 cm below and above the pupil), and the horizontal EOG (HEOG) signal was recorded from the outer canthus. EEG and EOG signals were filtered online with a band pass filter of 0.1–30 Hz, and they were digitized at 500 Hz using Neuroscan Synamps. All of the electrodes were referenced to the right earlobe. Electrode impedances did not exceed 2 k.\n",
        "\n",
        "**Experimental Protocol**\n",
        "\n",
        "The standard three-stimuli protocol [10], [12] was employed in this study. The participants were randomly divided into two groups: a guilty group and an innocent group. Six different jewels were prepared, and their pictures served as stimuli during detection. A safe that contained one (for the innocent) or two (for the guilty) jewels was given to each participant. They were instructed to open the safe and memorize the details of the object. We instructed the guilty group to steal only one object which would serve as the P stimulus. The other object in the safe was the T stimulus, and the remaining four pictures were the I stimuli. The object in the safe was not stolen for the innocent, which served as the T stimulus. Then, from the remaining five pictures, one picture was selected randomly and set as the P stimulus, and the remaining four images were set as I stimuli. All of the subjects were instructed to write down the information on the objects in the safe, such as the styles and colors of the jewels.\n",
        "\n",
        "After the preparation tasks introduced above, the participants began to perform the detection. They were seated in a chair, facing a video screen that was approximately 1 m away from their eyes. The stimuli pictures were presented randomly on the screen. Each item remained for 0.5 s with 30 iterations for one session, and each session lasted for approximately 5 minutes, with 2 minutes of resting time. The inter-stimulus interval was 1.6 s. Each subject was instructed to perform 5 sessions. The stimuli sequence diagram is given in Figure 1. One push button was given to each subject, and he or she was asked to press a “Yes” and “No” button when faced with familiar and unknown items, respectively.\n",
        "\n",
        "\n",
        "\n",
        "The guilty group was instructed to press the “Yes” and “No” button when faced with the T and I stimuli, respectively. With a P stimulus, they were asked to press the “No” button, attempting to hide the stolen act. In contrast, the innocent group made honest responses to all of the stimuli. All of the subjects had practiced the tasks above before the EEG signals were recorded formally. We planned to exclude any subjects that had more than a 5% clicking error, but none fell into this category. Finally, a sketch map is presented and shown in Figure 2 to describe above protocol.\n",
        "\n"
      ],
      "metadata": {
        "id": "qGQdDl_-ZPyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2QkYOYHvZ7cS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LIBRARIES AND PACKAGES"
      ],
      "metadata": {
        "id": "h-1xfQewfu85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rarfile"
      ],
      "metadata": {
        "id": "dCFMXUYkfsoq",
        "outputId": "7430c4d0-228f-4901-9bcd-7f3ab286e16e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset"
      ],
      "metadata": {
        "id": "ZWXAo_mGf3RZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82w6nI2EevuE",
        "outputId": "e60dcdb0-1872-4e09-cfa6-1bcd23c08953"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip folder\n",
        "zip_path = '/content/drive/MyDrive/dryad.zip'\n",
        "\n",
        "# Destination directory to unzip files\n",
        "destination_dir = 'dyrad/'\n",
        "\n",
        "# Create destination directory if it does not exist\n",
        "if not os.path.exists(destination_dir):\n",
        "    os.makedirs(destination_dir)\n",
        "\n",
        "# Unzip the folder\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_dir)\n",
        "\n",
        "# Access the files\n",
        "for root, dirs, files in os.walk(destination_dir):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "        print(f'File found: {file_path}')\n",
        "        # You can now perform any operations on the files\n"
      ],
      "metadata": {
        "id": "lTmpXnjgZOy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6cc333-c57a-44b2-e1d1-99ca136a14ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found: dyrad/All data for 14 electrodes and 30 subjects.rar\n",
            "File found: dyrad/README_for_All data for 14 electrodes and 30 subjects.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KLeCIMzWY2xI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e219ef-1be5-49ee-ffcb-f7a46be205ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Each stimuli item remained for 0.5 s with 30 iterations for one session. The inter-stimulus interval was 1.6 s. \n",
            "Each subject was instructed to perform 5 sessions. \n",
            "1.There are two folder \"lying\" and \"honest\" in dataset. In each folder, there are 15 subjects' data.\n",
            "2. In each subject's folder, there are 5 subfolder containing related data files for 5 sessions. \n",
            "3. In each session's folder, there are 3 files in 3 corresponding folder. For example, in the second session for the subject called subject3,\n",
            "you can open \" .\\lying\\subject3\\session2\" folder, and you can find three files: irrelevent.txt, probe.txt and target.txt.\n",
            "4. For each files, such as \" .\\lying\\subject3\\session2\\irrelevant\\irrelevant.txt\", it was all the response EEG signal for irrelevant stimuli.\n",
            "you can use EEGLAB toolbox open it and segment them into many epoched datasets.\n",
            " \n"
          ]
        }
      ],
      "source": [
        "# Path to the text file\n",
        "txt_file_path = '/content/dyrad/README_for_All data for 14 electrodes and 30 subjects.txt'\n",
        "\n",
        "# Read and display the contents of the text file\n",
        "with open(txt_file_path, 'r') as file:\n",
        "    contents = file.read()\n",
        "    print(contents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rarfile\n",
        "import os\n",
        "\n",
        "# Path to the rar file\n",
        "rar_path = '/content/dyrad/All data for 14 electrodes and 30 subjects.rar'\n",
        "\n",
        "# Destination directory to extract files\n",
        "destination_dir = 'dyrad/'\n",
        "\n",
        "# Create destination directory if it does not exist\n",
        "if not os.path.exists(destination_dir):\n",
        "    os.makedirs(destination_dir)\n",
        "\n",
        "# Open and extract the rar file\n",
        "with rarfile.RarFile(rar_path) as rf:\n",
        "    rf.extractall(destination_dir)\n",
        "\n",
        "# Access the extracted files\n",
        "for root, dirs, files in os.walk(destination_dir):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "        #print(f'File found: {file_path}')\n",
        "\n"
      ],
      "metadata": {
        "id": "VhVMaJUZfbrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dP0J2dqogb9_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}